{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Protecting Life Data Preparation Script\n",
    "\n",
    "- Version 1.2.1 - NHS Pycom Version Built - 22/05/2022\n",
    "- Version 1.1.3 - Current Version Demo delivered to Divisional Management - 14/04/2022\n",
    "- Version 1.1.2 - Abstract Submitted to BSG Conference 2022 - 25/02/2022\n",
    "- Version 1.1.1 - Basic MVP Built - 23/02/2022\n",
    "\n",
    "#### Authors:\n",
    "\n",
    "1. Matt Stammers - Consultant Gastroenterolgist and Data Scientist @ AXIS, UHS\n",
    "2. Michael George - Data Engineering Lead @ AXIS, UHS\n",
    "\n",
    "What this Script Does:\n",
    "- Loads in the data prepared by the data preparation script\n",
    "- Performs mass statistical descripitve analysis on the data after dividing the cohorts into two groups\n",
    "- Performs further statistical analysis on the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The first stage in an analytics package is to load in the analytics packages - ideally keeping this a slim as possible\n",
    "\n",
    "We have tried to use only a fairly simple selection of packages in this analytics pipeline - this then makes it much easier to build upon later on. Where possible we have coded out statistical functions ourselves to make the code even easier to understand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Key Packages\n",
    "\n",
    "# Import base packages\n",
    "import math\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "\n",
    "# Import data manipulation packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Import Statistical Packages\n",
    "\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Import Plotting Packages\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pandas settings adjustment\n",
    "\n",
    "Typically when performing analytics I like to adjust the base pandas settings for maximal customisability. This is up to you but if you want to change the settings you can below in any way you wish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust settings to see entire frame:\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('mode.chained_assignment', 'warn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below is the funciton block. Here we define our own user-generated functions to help with learning\n",
    "\n",
    "We have written these out bespoke. You can just use the ones contained in other packages but for the sake of learning and clarity we have written out the functions bespoke unless they are contained as defaults within numpy and pandas in which case they are highly reliable. If you spot a mistake please let us know!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical Functions\n",
    "\n",
    "def IQR(x):\n",
    "    \"\"\"Computes Interquartile Range\"\"\"\n",
    "    lb = stats.scoreatpercentile(x, 25) # Calculates 25th percentile\n",
    "    ub = stats.scoreatpercentile(x, 75) # Calculates 75th percentile\n",
    "    return ub - lb # Subtracts one from the other\n",
    "\n",
    "def IQR_lower(x):\n",
    "    \"\"\"Computes Interquartile Range Lower Quartile\"\"\"\n",
    "    lb = stats.scoreatpercentile(x, 25) # Calculates 25th percentile\n",
    "    return lb\n",
    "\n",
    "def IQR_upper(x):\n",
    "    \"\"\"Computes Interquartile Range Upper Quartile\"\"\"\n",
    "    ub = stats.scoreatpercentile(x, 75) # Calculates 75th percentile\n",
    "    return ub\n",
    "\n",
    "def CI_lower(x):\n",
    "    \"\"\"Computes 95% Confidence Interval Lower Bound of the Mean\"\"\"\n",
    "    alpha = 0.05                       # significance level = 5%\n",
    "    degfree = len(x) - 1                  # degress of freedom\n",
    "    t = stats.t.ppf(1 - alpha/2, degfree)   # 95% confidence t-score \n",
    "    s = np.std(x)          # sample standard deviation \n",
    "    n = len(x)\n",
    "    m = np.mean(x)\n",
    "    return  round(m - (t * s / np.sqrt(n)),4)\n",
    "\n",
    "def CI_upper(x):\n",
    "    \"\"\"Computes 95% Confidence Interval Upper Bound of the Mean\"\"\"\n",
    "    alpha = 0.05                       # significance level = 5%\n",
    "    degfree = len(x) - 1                  # degress of freedom\n",
    "    t = stats.t.ppf(1 - alpha/2, degfree)   # 95% confidence t-score \n",
    "    s = np.std(x)          # sample standard deviation \n",
    "    n = len(x)\n",
    "    m = np.mean(x)\n",
    "    return  round(m + (t * s / np.sqrt(n)),4)\n",
    "\n",
    "def CI_lower_median(x):\n",
    "    \"\"\"Computes 95% Confidence Interval Lower Bound of the Median\"\"\"\n",
    "    alpha = 0.05                       # significance level = 5%\n",
    "    degfree = len(x) - 1                  # degress of freedom\n",
    "    t = stats.t.ppf(1 - alpha/2, degfree)   # 95% confidence t-score \n",
    "    s = np.std(x)          # sample standard deviation \n",
    "    n = len(x)\n",
    "    m = np.median(x)\n",
    "    return  round(m - (t * s / np.sqrt(n)),4)\n",
    "\n",
    "def CI_upper_median(x):\n",
    "    \"\"\"Computes 95% Confidence Interval Upper Bound of the Median\"\"\"\n",
    "    alpha = 0.05                       # significance level = 5%\n",
    "    degfree = len(x) - 1                  # degress of freedom\n",
    "    t = stats.t.ppf(1 - alpha/2, degfree)   # 95% confidence t-score \n",
    "    s = np.std(x)          # sample standard deviation \n",
    "    n = len(x)\n",
    "    m = np.median(x)\n",
    "    return  round(m + (t * s / np.sqrt(n)),4)\n",
    "    \n",
    "# To calculate estimated cumulative distribution functions if required\n",
    "    \n",
    "def ecdf(data):\n",
    "    \"\"\"Compute ECDF for a one-dimensional array of measurements.\"\"\"\n",
    "    # Number of data points: n\n",
    "    n = len(data)\n",
    "    # x-data for the ECDF: x\n",
    "    x = np.sort(data)\n",
    "    # y-data for the ECDF: y\n",
    "    y = np.arange(1, n+1) / n\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load in the Datasets\n",
    "\n",
    "Now we are ready to load in the datasets from the processing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
