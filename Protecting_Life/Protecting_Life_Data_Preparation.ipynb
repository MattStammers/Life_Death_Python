{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Protecting Life Data Preparation Script\n",
    "\n",
    "- Version 1.2.1 - NHS Pycom Version Built - 22/05/2022\n",
    "- Version 1.1.3 - Current Version Demo delivered to Divisional Management - 14/04/2022\n",
    "- Version 1.1.2 - Abstract Submitted to BSG Conference 2022 - 25/02/2022\n",
    "- Version 1.1.1 - Basic MVP Built - 23/02/2022\n",
    "\n",
    "#### Authors:\n",
    "\n",
    "1. Matt Stammers - Consultant Gastroenterolgist and Data Scientist @ AXIS, UHS\n",
    "2. Michael George - Data Engineering Lead @ AXIS, UHS\n",
    "\n",
    "What this Script Does:\n",
    "- Finds patients who have suffered an acute gastrointestinal bleed and identifies their index admission.\n",
    "- Obtains key risk factors for death and key information documenting the admission.\n",
    "- Risk stratifies patient mortality by validated risk scoring systems (CCI and HFRS) using comorbidipy (see documentation).\n",
    "- Deposit the results into a flat file on the network for use by clinical teams or for further subsequent analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datetime Packages\n",
    "import datetime as datetime\n",
    "\n",
    "# Database Connectors\n",
    "import cx_Oracle as cxo\n",
    "import sqlalchemy as sqla\n",
    "from sqlalchemy import create_engine, MetaData, Table, and_\n",
    "from sqlalchemy.sql import select\n",
    "\n",
    "# Pandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Encryption\n",
    "import keyring\n",
    "\n",
    "# Risk Scoring\n",
    "from comorbidipy import comorbidity\n",
    "from comorbidipy import hfrs\n",
    "\n",
    "# Print version of sqlalchemy\n",
    "print(sqla.__version__)  \n",
    "\n",
    "# Print if the cx_Oracle is recognized\n",
    "print(cxo.version)   \n",
    "\n",
    "# Setup Connection to Client\n",
    "\n",
    "cxo.init_oracle_client(lib_dir= \"{path to client}/instantclient_11_2/\")\n",
    "\n",
    "# Print client version\n",
    "print(cxo.clientversion())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A note on Flat Files\n",
    "\n",
    "If you want to run flat files instead of connecting to the database you should do so here. For instance if you have a .csv file or set of .csv files with the relevant data in them you can import them as per the following:\n",
    "\n",
    "```python\n",
    "df_comorb = pd.read_csv('{path to file}/comorbidity_data.csv')\n",
    "```\n",
    "\n",
    "We would however recommend setting up a database connection to this as it is going to be far more scalable as you will see below. You will need your local IT team's help to set this up but once you have access credentials they can be stored using keyring as below:\n",
    "\n",
    "```python\n",
    "keyring.set_password('User', '1', 'jimminycrickets')\n",
    "```\n",
    "\n",
    "Once you have set this up as long as you remember how you stored everything it can easily be retrieved by switching set to get_password as below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A note on connecting to a database\n",
    "\n",
    "In this example we are connecting to an Oracle SQL database using the SQLAlchemy library.\n",
    "\n",
    "One method of connecting your database via SQLAlchemy is using an Engine. This is done by passing in a 'Database URL' to the create_engine() function. These database URLS follow a particular protocol and generally include the username, password, hostname and database name, and some other optional keyword arguments for additional configuration (in our example we have included a service_name configuration option to connect to the Oracle database)\n",
    "\n",
    "A typical database url looks like this:\n",
    "\n",
    "```python\n",
    "dialect+driver://username:password@host:port/database\n",
    "```\n",
    "\n",
    "For more details you can refer to the SQLAlchemy documentation regarding engines and how to construct a database url for your particualr hospitals database: https://docs.sqlalchemy.org/en/14/core/engines.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in Connection Credentials\n",
    "\n",
    "ora_user = keyring.get_password(\"User\", \"10\")\n",
    "ora_password = keyring.get_password(\"Password\", \"10\")\n",
    "ora_host = keyring.get_password(\"Host\", \"10\")\n",
    "ora_service = keyring.get_password(\"Service\", \"10\")\n",
    "ora_port = keyring.get_password(\"Port\", \"10\")\n",
    "\n",
    "# Set Key Connection Variables\n",
    "\n",
    "DIALECT = 'oracle'\n",
    "SQL_DRIVER = 'cx_oracle'\n",
    "USERNAME = ora_user\n",
    "PASSWORD = ora_password\n",
    "HOST = ora_host\n",
    "PORT = ora_port\n",
    "SERVICE = ora_service\n",
    "\n",
    "# Create Engine Authorisation String Without Exposing Credentials\n",
    "ENGINE_PATH_WIN_AUTH = f'{DIALECT}+{SQL_DRIVER}://{USERNAME}:{PASSWORD}@{HOST}:{str(PORT)}/?service_name={SERVICE}'\n",
    "# ENGINE_PATH_WIN_AUTH = DIALECT + '+' + SQL_DRIVER + '://' + USERNAME + ':' + PASSWORD +'@' + HOST + ':' + str(PORT) + '/?service_name=' + SERVICE\n",
    "\n",
    "# Create and Connect to Engine\n",
    "\n",
    "engine = create_engine(ENGINE_PATH_WIN_AUTH)\n",
    "engine.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A note when learning\n",
    "\n",
    "When you are learning to do the above we recommend breaking this block up into smaller subcomponents until you have mastered each of them. It will be worth the effort to learn how to do this. Once you have done it you can then connect to your SQL Queries\n",
    "\n",
    "#### SQL Queries and Extract\n",
    "\n",
    "These SQL queries are pseudocode to help you get the idea behind the approach and why it is being achieved this way. If you however insert the SQL in this format between the comments and then parse it through the engine it will work. For the sake of simplicity I have generated individual queries for the different components however some of the connections could be made database-side but we are deliberately assuming little SQL knowledge in this script to make the process easier to understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finds all the patients who have had a gastrointestinal bleed within the hospital\n",
    "\n",
    "GI_Bleed_Query = \"\"\"\n",
    "SELECT {insert columns of interest}\n",
    "FROM {endoscopy table}\n",
    "{LEFT/INNER/OUTER} JOIN {insert tables of interest}\n",
    "WHERE {filters of interest - in this case patients with meleana, haematemesis or 'coffee ground vomiting'}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now you can create your index cohort\n",
    "\n",
    "From this you can filter the subsequent queries. This is often better done using SQL itself but if you do want to do it using python this will work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This gets you the GI Bleed cohort\n",
    "\n",
    "df_bleeding = pd.read_sql_query(GI_Bleed_Query, engine)\n",
    "\n",
    "# Patients who bled\n",
    "\n",
    "patients_who_bled = tuple(df_bleeding['patient_id'].to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now run the other queries in sequence \n",
    "\n",
    "This enables you to gather your cohort with the first query and then cross-filter the results with subsequent queries. See below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other Queries\n",
    "\n",
    "# Finds key patient demographics\n",
    "\n",
    "Demographics_Query = \"\"\"\n",
    "SELECT {insert columns of interest - probably patient table or like}\n",
    "FROM {main presumably patient table}\n",
    "{LEFT/INNER/OUTER} JOIN {insert tables of interest}\n",
    "WHERE {filters of interest - in this case filtered on the patient number from the Bleeding Query}\n",
    "PATIENT_IDENTIFIER IN {} /* inserts the patient identifiers */\n",
    "\"\"\".format(patients_who_bled)\n",
    "\n",
    "# Comorbidity Query\n",
    "\n",
    "Comorbidity_Query = \"\"\"\n",
    "SELECT {insert columns of interest - likely ICD10/SNOMED codes}\n",
    "FROM {main ICD10/SNOMED table}\n",
    "{LEFT/INNER/OUTER} JOIN {other important ICD10/SNOMED tables}\n",
    "WHERE {filters of interest - in this case filtered on the patient number from the Bleeding Query}\n",
    "PATIENT_IDENTIFIER IN {} /* inserts the patient identifiers */\n",
    "ORDER BY {perhaps by date or code}\n",
    "\"\"\".format(patients_who_bled)\n",
    "\n",
    "# Admissions Query\n",
    "\n",
    "Admissions_Query = \"\"\"\n",
    "SELECT {insert columns of interest - likely admissions data}\n",
    "FROM {main discharge summary table}\n",
    "{LEFT/INNER/OUTER} JOIN {other important tables if needed}\n",
    "WHERE {filters of interest - in this case filtered on the patient number from the Bleeding Query}\n",
    "PATIENT_IDENTIFIER IN {} /* inserts the patient identifiers */\n",
    "\"\"\".format(patients_who_bled)\n",
    "\n",
    "# Physiology Query\n",
    "\n",
    "Physiology_Query = \"\"\"\n",
    "SELECT {insert columns of interest - likely weight and height rather than BMI}\n",
    "FROM {main physiology data table}\n",
    "{LEFT/INNER/OUTER} JOIN {probably not required}\n",
    "WHERE {filters of interest - in this case filtered on the patient number from the Bleeding Query and perhaps time}\n",
    "PATIENT_IDENTIFIER IN {} /* inserts the patient identifiers */\n",
    "\"\"\".format(patients_who_bled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You can now connect your engine to these queries to create the dataframes\n",
    "\n",
    "Now by connecting the engines to the queries you can pull all relevant data through"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This makes it very easy to pull discrete up to date datasets from your EPR/PAS into the kernel\n",
    "\n",
    "df_demographics = pd.read_sql_query(Demographics_Query, engine)\n",
    "df_comorbidity = pd.read_sql_query(Comorbidity_Query, engine)\n",
    "df_admissions = pd.read_sql_query(Admissions_Query, engine)\n",
    "df_physiology = pd.read_sql_query(Physiology_Query, engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building the Index Database\n",
    "\n",
    "In this case we need to build the index dataframe first as we are only interested in index or first admissions. To get these we combine the bleed and admission databases and filter them to extract only the first relevant admission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datetime Function - to turn all column strings containing 'date' or 'datetime' into datetimes\n",
    "\n",
    "def Datetime(series):\n",
    "    if ('date' in series.name.lower() or 'datetime' in series.name.lower()) and 'age' not in series.name.lower():\n",
    "            series = pd.to_datetime(series, dayfirst = True)\n",
    "    return series\n",
    "\n",
    "# First convert all the relevant rows in the key dataframes\n",
    "\n",
    "df_admissions = df_admissions.apply(Datetime)\n",
    "df_bleeding = df_bleeding.apply(Datetime)\n",
    "\n",
    "# Then join the tables so we can select only the relevant admissions\n",
    "\n",
    "df_bleeds_and_admissions = pd.merge(df_bleeding, df_admissions, on='patient_id', how='left')\n",
    "\n",
    "# Now filter to select only the bleed endoscopies which occurred during an admission\n",
    "\n",
    "df_admitted_bleeds = df_bleeds_and_admissions[df_bleeds_and_admissions['date_of_endoscopy'].between(df_bleeds_and_admissions['admission_date'], df_bleeds_and_admissions['discharge_date'])]\n",
    "\n",
    "# Finally select out only the first or index admission as this is what we are interested in. Subsequent admissions are handled seperately\n",
    "\n",
    "df_first_adm = df_key.loc[df_key.groupby('Procedure Date')['ipe_admissiondate'].idxmin()]\n",
    "df_first_adm.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we want to assess only the relevant BMI of these patients\n",
    "\n",
    "We do not want to have all the BMI's - only those that pertain to the time of the gastrointestinal bleeds. We can collect this using a similar strategy to the above one of filtering the values to make sure they occur only after the index admission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First extract the weights and heights from the data to create two seperate pandas series\n",
    "\n",
    "df_heights = df_physiology[df_physiology['test_code'] == 'HEIG']\n",
    "df_weights = df_physiology[df_physiology['test_code'] == 'WEIG']\n",
    "\n",
    "# Then aggregate them - we settled for mean in the end after checking for skewness\n",
    "\n",
    "df_heights2 = df_heights.groupby(['patient_id']).agg('mean').reset_index()\n",
    "df_weights2 = df_weights.groupby(['patient_id']).agg('mean').reset_index()\n",
    "\n",
    "# Rename the columns\n",
    "\n",
    "df_weights2.columns = ['PATIENT_ID', 'MEAN_WEIGHT']\n",
    "df_heights2.columns = ['PATIENT_ID', 'MEAN_HEIGHT']\n",
    "\n",
    "# Join Together\n",
    "df_bmi = pd.concat([df_heights2, df_weights2])\n",
    "\n",
    "# Then convert height to meters if currently in centimeters and calc BMI\n",
    "\n",
    "df_bmi['MEAN_HEIGHT_M'] = df_bmi['MEAN_HEIGHT']/100\n",
    "df_bmi['BMI'] = round(df_bmi['MEAN_WEIGHT']/(df_bmi['MEAN_HEIGHT_M'])**2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First merge the core cohort to the demographics and then add the BMI data\n",
    "\n",
    "df_merge1 = pd.merge(df_index_scope, df_demographics, on='patient_id', how = 'left')\n",
    "df_merge2 = pd.merge(df_merge1, df_bmi, on='patient_id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First create a subframe with the key columns\n",
    "\n",
    "comorbidities = df_merge2[['code', 'patient_id', 'age']]\n",
    "comorbidities.columns = ['code', 'id', 'age']\n",
    "\n",
    "# Then calculate the scores. Comorbidipy needs them in this format to work properly\n",
    "\n",
    "cci = comorbidity(comorbidities)\n",
    "frail = hfrs(comorbidities)\n",
    "\n",
    "# Then tidy up the outputs a bit\n",
    "\n",
    "cci['survival_10yr'] = round(cci['survival_10yr']*100,1).astype(str)\n",
    "cci['survival_10yr'] = cci['survival_10yr'].apply(lambda x: ''.join(x + \"%\"))\n",
    "\n",
    "# Then join these tables into one and add back to the main dataframe to create merge3\n",
    "\n",
    "comorb_merge = pd.merge(cci, frail, on='id', how='left')\n",
    "df_merge3_added = pd.merge(df_merge2, comorb_merge, left_on='patient_id', right_on='id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datetime Function - to turn all column strings containing 'date' or 'datetime' into datetimes\n",
    "\n",
    "def Datetime(series):\n",
    "    if ('date' in series.name.lower() or 'datetime' in series.name.lower()) and 'age' not in series.name.lower():\n",
    "            series = pd.to_datetime(series, dayfirst = True)\n",
    "    return series\n",
    "\n",
    "df_admissions = df_admissions.apply(Datetime)\n",
    "df_bleeding = df_bleeding.apply(Datetime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
